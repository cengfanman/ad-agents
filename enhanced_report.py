"""Enhanced report generation with OpenAI integration for human-friendly analysis."""

import os
import json
from typing import Dict, Any, Optional
from pathlib import Path
from datetime import datetime

# Load .env file
try:
    from dotenv import load_dotenv
    load_dotenv(override=True)
except ImportError:
    pass

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class EnhancedReportGenerator:
    """Generate enhanced human-friendly reports using OpenAI."""
    
    def __init__(self, language='en'):
        self.openai_client = None
        self.language = language
        if OPENAI_AVAILABLE:
            api_key = os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = openai.OpenAI(api_key=api_key)
    
    def generate_enhanced_report(self, result: dict, scenario_input, trace_data: dict = None) -> Optional[str]:
        """Generate an enhanced report with human-friendly analysis and visualizations."""
        
        if not self.openai_client:
            return None
            
        try:
            # Prepare context data
            context = self._prepare_analysis_context(result, scenario_input, trace_data)
            
            # Generate human-friendly analysis
            analysis = self._generate_analysis_with_ai(context)
            
            if analysis:
                # Generate the enhanced markdown report
                enhanced_report = self._create_enhanced_markdown(analysis, result, scenario_input, trace_data)
                
                # Save to file
                return self._save_report(enhanced_report, scenario_input.asin)
                
        except Exception as e:
            print(f"[dim yellow]âš ï¸  Enhanced report generation failed: {str(e)}[/dim yellow]")
            import traceback
            print(f"[dim]Full traceback: {traceback.format_exc()}[/dim]")
            return None
        
        return None
    
    def _prepare_analysis_context(self, result: dict, scenario_input, trace_data: dict) -> str:
        """Prepare detailed step-by-step execution context for AI analysis."""
        
        goal = scenario_input.goal
        asin = scenario_input.asin
        
        # Extract detailed execution steps
        execution_details = []
        if trace_data and 'execution_trace' in trace_data:
            step_counter = 0
            current_step = {}
            
            for entry in trace_data['execution_trace']:
                entry_type = entry['type']
                data = entry['data']
                
                if entry_type == 'decision' and 'selected_tool' in data:
                    step_counter += 1
                    current_step = {
                        'step': step_counter,
                        'tool': data['selected_tool'],
                        'reasoning': data.get('reasoning', 'No reasoning provided')
                    }
                
                elif entry_type == 'action' and 'result' in data and current_step:
                    tool_result = data['result']
                    current_step['success'] = tool_result['ok']
                    current_step['findings'] = tool_result.get('data', {})
                    current_step['error'] = tool_result.get('error', '') if not tool_result['ok'] else None
                    
                elif entry_type == 'update' and 'belief_changes' in data and current_step:
                    current_step['belief_changes'] = data['belief_changes']
                    # Step is complete, add it to execution details
                    execution_details.append(current_step)
                    current_step = {}
        
        # Format execution steps for AI
        steps_text = ""
        for step_info in execution_details:
            status = "âœ… Success" if step_info.get('success') else "âŒ Failed"
            steps_text += f"""
Step {step_info['step']}: {step_info['tool']} {status}
- Reasoning: {step_info.get('reasoning', 'No reasoning')}
- Findings: {self._format_findings(step_info.get('findings', {}))}
"""
            if step_info.get('error'):
                steps_text += f"- Error: {step_info['error']}\n"
            
            # Add belief changes
            if step_info.get('belief_changes'):
                steps_text += "- Belief Updates:\n"
                for hyp, changes in step_info['belief_changes'].items():
                    old = changes.get('old', 0)
                    new = changes.get('new', 0)
                    if abs(new - old) > 0.01:
                        arrow = "â†—ï¸" if new > old else "â†˜ï¸"
                        steps_text += f"  * {hyp}: {old:.2f} â†’ {new:.2f} {arrow}\n"
            steps_text += "\n"
        
        context = f"""
Amazon Advertising Agent Execution Analysis:

ASIN: {asin}
Goal: {goal}

Please analyze this step-by-step execution and provide insights into the agent's reasoning process, what it discovered at each step, and how it arrived at its conclusions.

DETAILED EXECUTION STEPS:
{steps_text}

Focus on explaining:
1. The agent's decision-making process at each step
2. What each tool revealed and why it was important
3. How the agent's understanding evolved through the process
4. Any challenges or errors encountered and how they were handled
"""
        return context
    
    def _format_findings(self, findings: dict) -> str:
        """Format tool findings in a readable way."""
        if not findings:
            return "No specific findings recorded"
        
        # Extract key metrics and information
        key_info = []
        for key, value in findings.items():
            if key in ['quality_score', 'grade', 'issues_found']:
                key_info.append(f"{key.replace('_', ' ')}: {value}")
            elif key in ['total_impressions', 'overall_ctr', 'overall_acos']:
                key_info.append(f"{key.replace('_', ' ')}: {value}")
            elif key in ['competitive_pressure', 'price_positioning']:
                key_info.append(f"{key.replace('_', ' ')}: {value}")
        
        return "; ".join(key_info) if key_info else str(findings)[:100]
    
    def _generate_analysis_with_ai(self, context: str) -> Optional[dict]:
        """Use OpenAI to generate human-friendly analysis."""
        
        if self.language == 'zh-tw':
            language_instruction = "è«‹ç”¨ç¹é«”ä¸­æ–‡å›žè¦†ï¼Œä¸¦æä¾›è±å¯Œè©³ç´°çš„è§£é‡‹ã€‚"
            prompt = f"""ä½ æ­£åœ¨åˆ†æžä¸€å€‹ç”¨æ–¼è¨ºæ–·Amazonå»£å‘Šå•é¡Œçš„AIä»£ç†çš„é€æ­¥åŸ·è¡ŒéŽç¨‹ã€‚ä½œç‚ºä¸€ä½å°ˆæ¥­çš„AIæ•™å­¸å°ˆå®¶ï¼Œè«‹è©³ç´°è§£é‡‹ä»£ç†çš„æŽ¨ç†éŽç¨‹ï¼Œè®“è®€è€…èƒ½æ·±å…¥ç†è§£AIå¦‚ä½•æ€è€ƒå’Œå­¸ç¿’ã€‚

{context}

è«‹æä¾›éžå¸¸è©³ç´°çš„åˆ†æžï¼Œçµæ§‹åŒ–å¦‚ä¸‹ï¼š

1. EXECUTION_OVERVIEWï¼š
   - è©³ç´°æè¿°ä»£ç†çš„æ•´é«”ç­–ç•¥å’Œæ–¹æ³•è«–
   - è§£é‡‹ç‚ºä»€éº¼é¸æ“‡é€™ç¨®æ–¹æ³•ä¾†è§£æ±ºå•é¡Œ
   - èªªæ˜Žä»£ç†å¦‚ä½•è¨­å®šåˆå§‹å‡è¨­å’Œç›®æ¨™

2. STEP_BY_STEP_ANALYSISï¼š
   - å°æ¯ä¸€æ­¥é©Ÿé€²è¡Œæ·±å…¥åˆ†æžï¼ŒåŒ…æ‹¬ï¼š
     * ä»£ç†åœ¨é€™ä¸€æ­¥çš„å…·é«”æ€è€ƒéŽç¨‹
     * ç‚ºä»€éº¼é¸æ“‡ä½¿ç”¨ç‰¹å®šå·¥å…·
     * å·¥å…·è¿”å›žçš„æ•¸æ“šæ„å‘³è‘—ä»€éº¼
     * é€™äº›ç™¼ç¾å¦‚ä½•å½±éŸ¿ä»£ç†çš„ä¸‹ä¸€æ­¥æ±ºç­–
     * ä»»ä½•æ„å¤–çš„çµæžœä»¥åŠä»£ç†å¦‚ä½•æ‡‰å°

3. REASONING_EVOLUTIONï¼š
   - è©³ç´°è¿½è¹¤ä»£ç†ä¿¡å¿µçš„è®ŠåŒ–è»Œè·¡
   - è§£é‡‹æ¯æ¬¡ä¿¡å¿µæ›´æ–°çš„é‚è¼¯ä¾æ“š
   - åˆ†æžä»£ç†å¦‚ä½•æ•´åˆæ–°è­‰æ“šå’ŒèˆŠçŸ¥è­˜
   - æè¿°ä»£ç†å­¸ç¿’å’Œé©æ‡‰çš„éŽç¨‹

4. DISCOVERY_INSIGHTSï¼š
   - æ·±å…¥è§£é‡‹æ¯å€‹é—œéµç™¼ç¾çš„å•†æ¥­å«ç¾©
   - åˆ†æžé€™äº›ç™¼ç¾å°Amazonå»£å‘Šç­–ç•¥çš„å½±éŸ¿
   - èªªæ˜Žä»£ç†å¦‚ä½•å¾žæ•¸æ“šä¸­æå–æ´žå¯Ÿ
   - è¨Žè«–ç™¼ç¾ä¹‹é–“çš„ç›¸äº’é—œè¯

5. PROCESS_EVALUATIONï¼š
   - è©•ä¼°ä»£ç†çš„æ±ºç­–å“è³ªå’Œé‚è¼¯æ€§
   - åˆ†æžä»£ç†è™•ç†ä¸ç¢ºå®šæ€§å’ŒéŒ¯èª¤çš„èƒ½åŠ›
   - è¨Žè«–ä»£ç†æŽ¨ç†éŽç¨‹çš„å„ªé»žå’Œå±€é™æ€§
   - æä¾›å°AIæŽ¨ç†æ©Ÿåˆ¶çš„æ·±åº¦è¦‹è§£

6. EDUCATIONAL_INSIGHTSï¼š
   - å¾žé€™å€‹æ¡ˆä¾‹ä¸­å¯ä»¥å­¸åˆ°å“ªäº›AIæŽ¨ç†åŽŸç†
   - è§£é‡‹ä»£ç†è¡Œç‚ºèƒŒå¾Œçš„æ©Ÿå™¨å­¸ç¿’æ¦‚å¿µ
   - è¨Žè«–é€™ç¨®AIæ–¹æ³•åœ¨å…¶ä»–å ´æ™¯çš„æ‡‰ç”¨æ½›åŠ›

è«‹ç”¨æ•™å­¸çš„èªžèª¿å¯«ä½œï¼ŒåŒ…å«è±å¯Œçš„è§£é‡‹å’Œä¾‹å­ï¼Œå¹«åŠ©è®€è€…ç†è§£AIæŽ¨ç†çš„è¤‡é›œæ€§å’Œç²¾å¦™ä¹‹è™•ã€‚{language_instruction}
"""
        else:
            prompt = f"""You are analyzing the step-by-step execution of an AI agent that diagnoses Amazon advertising issues. As a professional AI education expert, provide detailed explanations that help readers deeply understand how AI thinks and learns.

{context}

Please provide a comprehensive and detailed analysis structured as follows:

1. EXECUTION_OVERVIEW:
   - Detailed description of the agent's overall strategy and methodology
   - Explain why this approach was chosen to solve the problem
   - Describe how the agent set initial hypotheses and goals

2. STEP_BY_STEP_ANALYSIS:
   - Deep analysis of each step, including:
     * The agent's specific thought process at this step
     * Why it chose to use a particular tool
     * What the tool's returned data means
     * How these findings influenced the agent's next decision
     * Any unexpected results and how the agent adapted

3. REASONING_EVOLUTION:
   - Detailed tracking of the agent's belief change trajectory
   - Explain the logical basis for each belief update
   - Analyze how the agent integrates new evidence with old knowledge
   - Describe the agent's learning and adaptation process

4. DISCOVERY_INSIGHTS:
   - In-depth explanation of the business implications of each key finding
   - Analyze how these discoveries impact Amazon advertising strategy
   - Explain how the agent extracts insights from data
   - Discuss the interconnections between findings

5. PROCESS_EVALUATION:
   - Evaluate the quality and logic of the agent's decisions
   - Analyze the agent's ability to handle uncertainty and errors
   - Discuss strengths and limitations of the agent's reasoning process
   - Provide deep insights into AI reasoning mechanisms

6. EDUCATIONAL_INSIGHTS:
   - What AI reasoning principles can be learned from this case
   - Explain the machine learning concepts behind agent behavior
   - Discuss the potential application of this AI approach in other scenarios

Write in an educational tone with rich explanations and examples to help readers understand the complexity and sophistication of AI reasoning.
"""

        try:
            system_content = "You are an expert AI educator and Amazon advertising consultant who provides detailed, educational explanations about AI reasoning and business insights." if self.language == 'en' else "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„AIæ•™è‚²å°ˆå®¶å’ŒAmazonå»£å‘Šé¡§å•ï¼Œæä¾›é—œæ–¼AIæŽ¨ç†å’Œå•†æ¥­æ´žå¯Ÿçš„è©³ç´°æ•™å­¸è§£é‡‹ã€‚"
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.7
            )
            
            content = response.choices[0].message.content
            return self._parse_ai_response(content)
            
        except Exception as e:
            print(f"OpenAI API error: {str(e)}")
            return None
    
    def _parse_ai_response(self, content: str) -> dict:
        """Parse the AI response into structured components."""
        # Simple fallback: if parsing fails, use the whole content as execution overview
        sections = {
            'EXECUTION_OVERVIEW': content.strip()[:500] + '...',
            'STEP_BY_STEP_ANALYSIS': 'â€¢ Agent executed systematic analysis of advertising performance',
            'REASONING_EVOLUTION': 'Agent updated beliefs based on evidence collected during execution',
            'DISCOVERY_INSIGHTS': 'Key insights were discovered through iterative tool execution',
            'PROCESS_EVALUATION': 'Agent demonstrated effective reasoning and evidence integration',
            'EDUCATIONAL_INSIGHTS': 'This case demonstrates key principles of AI reasoning and decision-making'
        }
        
        # Try to parse structured content if available
        keywords = ['EXECUTION_OVERVIEW', 'STEP_BY_STEP_ANALYSIS', 'REASONING_EVOLUTION', 'DISCOVERY_INSIGHTS', 'PROCESS_EVALUATION', 'EDUCATIONAL_INSIGHTS']
        current_section = None
        current_content = []
        
        for line in content.split('\n'):
            line = line.strip()
            
            # Check if this line contains any keyword
            found_keyword = None
            for keyword in keywords:
                if keyword.replace('_', ' ').upper() in line.upper() or keyword.upper() in line.upper():
                    found_keyword = keyword
                    break
            
            if found_keyword:
                # Save previous section
                if current_section and current_content:
                    sections[current_section] = '\n'.join(current_content).strip()
                
                # Start new section
                current_section = found_keyword
                # Extract content after keyword (remove markdown, numbers, colons)
                after_keyword = line
                for sep in [':', '**', '*', '1.', '2.', '3.', '4.', '5.']:
                    if sep in after_keyword:
                        parts = after_keyword.split(sep)
                        if len(parts) > 1:
                            after_keyword = sep.join(parts[1:])
                current_content = [after_keyword.strip()] if after_keyword.strip() else []
            elif current_section and line:
                current_content.append(line)
        
        # Save last section
        if current_section and current_content:
            sections[current_section] = '\n'.join(current_content).strip()
        
        return sections
    
    def _create_enhanced_markdown(self, analysis: dict, result: dict, scenario_input, trace_data: dict) -> str:
        """Create the enhanced markdown report."""
        
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M")
        
        # Generate ASCII chart placeholder based on AI suggestion
        chart_placeholder = self._generate_ascii_chart(result, analysis.get('CHART_SUGGESTION', ''))
        
        if self.language == 'zh-tw':
            report = f"""# ðŸ¤– AI ä»£ç†åŸ·è¡Œåˆ†æž
**ASIN:** {scenario_input.asin} | **ç›®æ¨™:** {scenario_input.goal} | **ç”Ÿæˆæ™‚é–“:** {timestamp}

---

## ðŸŽ¯ åŸ·è¡Œæ¦‚è¿°

{analysis.get('EXECUTION_OVERVIEW', 'AIä»£ç†åŸ·è¡Œäº†ç³»çµ±æ€§çš„å»£å‘Šæ•ˆèƒ½åˆ†æžã€‚')}

**æœ€çµ‚ä¿¡å¿ƒæ°´æº–:** {result.get('confidence', 0):.0%} | **ç¸½æ­¥æ•¸:** {result.get('total_steps', 'æœªçŸ¥')}

---

## ðŸ” é€æ­¥åˆ†æž

{analysis.get('STEP_BY_STEP_ANALYSIS', 'è©³ç´°æ­¥é©Ÿåˆ†æžä¸å¯ç”¨ã€‚')}

---

## ðŸ“ˆ ä»£ç†æŽ¨ç†æ¼”åŒ–

{analysis.get('REASONING_EVOLUTION', 'æŽ¨ç†æ¼”åŒ–æœªè¨˜éŒ„ã€‚')}

---

## ðŸ’¡ é—œéµç™¼ç¾

{analysis.get('DISCOVERY_INSIGHTS', 'é—œéµç™¼ç¾æœªè¨˜éŒ„ã€‚')}

---

## ðŸ æœ€çµ‚å‡è¨­æŽ’å

{chart_placeholder}

**ä»£ç†çµè«–:** {result.get('primary_hypothesis', 'æœªçŸ¥').replace('_', ' ').title()}

### æœ€çµ‚å»ºè­°è¡Œå‹•:
{chr(10).join([f"- {rec}" for rec in result.get('recommendations', [])[:3]])}

---

## ðŸ”¬ éŽç¨‹è©•ä¼°

{analysis.get('PROCESS_EVALUATION', 'éŽç¨‹è©•ä¼°ä¸å¯ç”¨ã€‚')}

---

## ðŸŽ“ æ•™å­¸æ´žå¯Ÿ

{analysis.get('EDUCATIONAL_INSIGHTS', 'AIæŽ¨ç†æ•™å­¸æ´žå¯Ÿä¸å¯ç”¨ã€‚')}

---

## ðŸ”§ åŸ·è¡Œè¿½è¹¤

### å·²åŸ·è¡Œçš„å·¥å…·:
{self._get_detailed_tools_trace(trace_data)}

### å‡è¨­ä¿¡å¿ƒåº¦æ¼”åŒ–:
{chr(10).join([f"- **{name.replace('_', ' ').title()}:** {belief:.0%}" for name, belief in result.get('all_hypotheses', {}).items()])}

---

*ðŸ¤– æ­¤å ±å‘Šä½¿ç”¨OpenAI GPT-4oé€æ­¥æŽ¨ç†åˆ†æžAIä»£ç†åŸ·è¡ŒéŽç¨‹*
"""
        else:
            report = f"""# ðŸ¤– AI Agent Execution Analysis
**ASIN:** {scenario_input.asin} | **Goal:** {scenario_input.goal} | **Generated:** {timestamp}

---

## ðŸŽ¯ Execution Overview

{analysis.get('EXECUTION_OVERVIEW', 'Agent executed systematic analysis of advertising performance.')}

**Final Confidence Level:** {result.get('confidence', 0):.0%} | **Total Steps:** {result.get('total_steps', 'Unknown')}

---

## ðŸ” Step-by-Step Analysis

{analysis.get('STEP_BY_STEP_ANALYSIS', 'Detailed step analysis not available.')}

---

## ðŸ“ˆ Agent's Reasoning Evolution

{analysis.get('REASONING_EVOLUTION', 'Reasoning evolution not documented.')}

---

## ðŸ’¡ Key Discoveries

{analysis.get('DISCOVERY_INSIGHTS', 'Key discoveries not documented.')}

---

## ðŸ Final Hypothesis Rankings

{chart_placeholder}

**Agent's Conclusion:** {result.get('primary_hypothesis', 'Unknown').replace('_', ' ').title()}

### Final Actions Recommended:
{chr(10).join([f"- {rec}" for rec in result.get('recommendations', [])[:3]])}

---

## ðŸ”¬ Process Evaluation

{analysis.get('PROCESS_EVALUATION', 'Process evaluation not available.')}

---

## ðŸŽ“ Educational Insights

{analysis.get('EDUCATIONAL_INSIGHTS', 'AI reasoning educational insights not available.')}

---

## ðŸ”§ Execution Trace

### Tools Executed:
{self._get_detailed_tools_trace(trace_data)}

### Hypothesis Confidence Evolution:
{chr(10).join([f"- **{name.replace('_', ' ').title()}:** {belief:.0%}" for name, belief in result.get('all_hypotheses', {}).items()])}

---

*ðŸ¤– This report analyzes AI agent execution with step-by-step reasoning powered by OpenAI GPT-4o*
"""
        
        return report
    
    def _generate_ascii_chart(self, result: dict, chart_suggestion: str) -> str:
        """Generate a simple ASCII chart based on hypothesis confidence scores."""
        
        hypotheses = result.get('all_hypotheses', {})
        if not hypotheses:
            return "No data available for visualization."
        
        # Create a simple horizontal bar chart
        chart_lines = ["```", "Hypothesis Confidence Levels:"]
        chart_lines.append("")
        
        # Sort by confidence
        sorted_hyps = sorted(hypotheses.items(), key=lambda x: x[1], reverse=True)
        
        for name, confidence in sorted_hyps[:5]:  # Top 5
            # Format name
            display_name = name.replace('h1_', '').replace('h2_', '').replace('h3_', '').replace('h4_', '').replace('h5_', '').replace('_', ' ').title()
            
            # Create bar (each â–  represents ~10%)
            bar_length = int(confidence * 10)
            bar = "â– " * bar_length + "â–¡" * (10 - bar_length)
            
            # Format line
            chart_lines.append(f"{display_name:<20} â”‚{bar}â”‚ {confidence:.0%}")
        
        chart_lines.extend(["", "```"])
        
        if 'chart' in chart_suggestion.lower() or 'bar' in chart_suggestion.lower():
            return "\n".join(chart_lines)
        else:
            return "\n".join(chart_lines) + f"\n\n*Suggested visualization: {chart_suggestion}*"
    
    def _get_tools_summary(self, trace_data: dict) -> str:
        """Get summary of tools used in execution."""
        if not trace_data or 'execution_trace' not in trace_data:
            return "Unknown"
            
        tools = set()
        for entry in trace_data['execution_trace']:
            if entry['type'] == 'action' and 'tool' in entry['data']:
                tools.add(entry['data']['tool'])
        
        return ", ".join(sorted(tools))
    
    def _get_detailed_tools_trace(self, trace_data: dict) -> str:
        """Get detailed trace of tool execution."""
        if not trace_data or 'execution_trace' not in trace_data:
            return "No execution trace available"
        
        trace_lines = []
        step_num = 0
        
        for entry in trace_data['execution_trace']:
            if entry['type'] == 'decision' and 'selected_tool' in entry['data']:
                step_num += 1
                tool = entry['data']['selected_tool']
                reasoning = entry['data'].get('reasoning', 'No reasoning provided')
                trace_lines.append(f"**Step {step_num}:** Selected `{tool}`")
                trace_lines.append(f"- *Reasoning:* {reasoning}")
            
            elif entry['type'] == 'action' and 'result' in entry['data']:
                result = entry['data']['result']
                status = "âœ… Success" if result['ok'] else "âŒ Failed"
                trace_lines.append(f"- *Result:* {status}")
                if not result['ok'] and 'error' in result:
                    trace_lines.append(f"- *Error:* {result['error']}")
                trace_lines.append("")
        
        return "\n".join(trace_lines)
    
    def _save_report(self, report_content: str, asin: str) -> str:
        """Save the enhanced report to a markdown file."""
        
        # Create reports directory
        reports_dir = Path("reports")
        reports_dir.mkdir(exist_ok=True)
        
        # Generate filename
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"analysis_{asin}_{timestamp}.md"
        filepath = reports_dir / filename
        
        # Save file
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(filepath)


def generate_enhanced_report(result: dict, scenario_input, trace_data: dict = None, language='en') -> Optional[str]:
    """Main function to generate enhanced report."""
    generator = EnhancedReportGenerator(language=language)
    return generator.generate_enhanced_report(result, scenario_input, trace_data)